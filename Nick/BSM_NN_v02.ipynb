{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of BSM_NN_v02.ipynb ",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickwotton/MQP2019/blob/master/Nick/BSM_NN_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu5uIyYP6Tnz",
        "colab_type": "text"
      },
      "source": [
        "# Attempt to Replicate the Black Scholes Model Using a Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KOvg3FsM7r51",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4PCo06270zm",
        "colab_type": "text"
      },
      "source": [
        "## Define the Function\n",
        "Here we define our function, the Black Scholes Model (BSM). First, we must initialize the option class, then the Geometric Brownian Motion Class, and finally the BSM class.\n",
        "Then we test the equation with a test value of 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wdyGtXXn7r56",
        "colab": {}
      },
      "source": [
        "'''=========\n",
        "option class init\n",
        "=========='''\n",
        "class VanillaOption:\n",
        "    def __init__(\n",
        "        self,\n",
        "        otype = 1, # 1: 'call'\n",
        "                  # -1: 'put'\n",
        "        strike = 110.,\n",
        "        maturity = 1.,\n",
        "        market_price = 10.):\n",
        "      self.otype = otype               # Put or Call\n",
        "      self.strike = strike             # Strike K\n",
        "      self.maturity = maturity         # Maturity T\n",
        "      self.market_price = market_price #this will be used for calibration\n",
        "      \n",
        "        \n",
        "    def payoff(self, s): #s: excercise price\n",
        "      otype = self.otype\n",
        "      k = self.strike\n",
        "      maturity = self.maturity\n",
        "      return np.max([0, (s - k)*otype])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZT5HETX8jIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''============\n",
        "Gbm class\n",
        "============='''\n",
        "\n",
        "class Gbm:\n",
        "    def __init__(self,\n",
        "                 init_state = 100.,\n",
        "                 drift_ratio = .0475,\n",
        "                 vol_ratio = .2\n",
        "                ):\n",
        "        self.init_state = init_state\n",
        "        self.drift_ratio = drift_ratio\n",
        "        self.vol_ratio = vol_ratio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkd7sAZCEYUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''========\n",
        "Black-Scholes-Merton formula. \n",
        "=========='''\n",
        "\n",
        "def bsm_price(self, vanilla_option):\n",
        "    s0 = self.init_state\n",
        "    sigma = self.vol_ratio\n",
        "    r = self.drift_ratio\n",
        "    \n",
        "    otype = vanilla_option.otype\n",
        "    k = vanilla_option.strike\n",
        "    maturity = vanilla_option.maturity\n",
        "    \n",
        "    d1 = 1/(sigma*np.sqrt(maturity))*(np.log(s0/k) + (r + np.power(sigma,2)/2)*(maturity)) \n",
        "    d2 = 1/(sigma*np.sqrt(maturity))*(np.log(s0/k) + (r - np.power(sigma,2)/2)*(maturity)) \n",
        "    return (otype * s0 * ss.norm.cdf(otype * d1) #line break needs parenthesis\n",
        "            - otype * np.exp(-r * maturity) * k * ss.norm.cdf(otype * d2))\n",
        "\n",
        "Gbm.bsm_price = bsm_price"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC1nkSnVIBgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''=======\n",
        "Get BSM prices given an option and a Tensor\n",
        "======='''\n",
        "\n",
        "def prices_bsm(self, vanilla_option, data):\n",
        "  \n",
        "  # Create the list\n",
        "  a = []\n",
        "\n",
        "  # Get tensor size\n",
        "  sizeT = list(data.size())[0]\n",
        "\n",
        "  for i in range(sizeT):\n",
        "    self.init_state = data[i].item()\n",
        "    callPrice = gbm1.bsm_price(vanilla_option)\n",
        "    a.append(callPrice)\n",
        "  \n",
        "  # Convert to array then tensor\n",
        "  arrayOut = np.array(a)\n",
        "  outputData = torch.from_numpy(arrayOut)\n",
        "  return outputData\n",
        "\n",
        "Gbm.prices_bsm = prices_bsm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoj7ImMqG5WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(s):\n",
        "  gbm = Gbm(init_state=s)\n",
        "  option = VanillaOption(strike=10)\n",
        "  return gbm.bsm_price(option)\n",
        "\n",
        "batch_size = 21\n",
        "x_list = np.linspace(8, 11, batch_size)\n",
        "y_list = np.array([f(x) for x in x_list])\n",
        "#plt.plot(x_list, y_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G7JVcog6Ref",
        "colab_type": "text"
      },
      "source": [
        "## Create Model\n",
        "Next, we create the neural network model. This is done first by setting the inner and outer dimensions with variables. Next we code the model and vary the internal dimensions to attempt to improve the model. At this level, this is essentially a simple linear algebra exercise:\n",
        "\n",
        "If we have input $x$, internal parameters $a,b$, and solution $f(x)$ then in the one-dimensional case we have:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\left(\n",
        "    a_{1}x+b_{2}\n",
        "  \\right)\n",
        "  a_{2} + b_{2}\n",
        "  = f(x)\n",
        "\\end{equation}\n",
        "  \n",
        "However, we want to get a better estimate for the true equation. So we increase the interior dimension which corresponds to the number of neurons inside the network. For example, we raised the inner dimension to 3. In matrix form we have:\n",
        "\n",
        "\\begin{equation}\n",
        "\\left(\n",
        "  \\begin{bmatrix} x \\end{bmatrix} \n",
        "  \\begin{bmatrix} a_{1} & a_{2} & a_{3} \\end{bmatrix} \n",
        "  + \n",
        "  \\begin{bmatrix} b_{1} & b_{2} & b_{3} \\end{bmatrix}\n",
        "\\right)\n",
        " \\begin{bmatrix} a_{4} \\\\ a_{5} \\\\ a_{6} \\end{bmatrix}\n",
        " +\n",
        " \\begin{bmatrix} b_{4} \\\\ \\end{bmatrix}\n",
        " =\n",
        " \\begin{bmatrix} f(x) \\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Graphically, we can render this second neural network as:\n",
        "![Neural Network Diagram](https://drive.google.com/uc?id=1ItiBpdjPvWHF5ZWy8JDNDKq6dXfyU-IE)\n",
        "\n",
        "**ADD DESCRIPTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiVUxudQ7r5_",
        "colab": {}
      },
      "source": [
        "#model\n",
        "#nn.Linear\n",
        "H1 = 50; H2 = 11 #number of hidden layer\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(1, H1), \n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(H1, H2),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(H2,2),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(2,1)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkuS30xvzTgV",
        "colab_type": "text"
      },
      "source": [
        "Here we define the Loss function as the Mean Squared Error(MSE). \n",
        "\n",
        "Note that by doing so, we are essentially 'cheating' the system. In most applications, we would not know the function $f$ so we would be unable to find the MSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7TqjOaLs7r6C",
        "colab": {}
      },
      "source": [
        "#loss function \n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIblNHIrzt8f",
        "colab_type": "text"
      },
      "source": [
        "Next we choose a learning rate and a method for learning. The learning rate is the percent of the data that is accepted in each iteration. The Methods we tried were SGD and Adam. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E4rnJCtA7r6G",
        "colab": {}
      },
      "source": [
        "#optimizer\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.7) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3ez3tCHHSum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = np.size(x_list)\n",
        "x_train0 = torch.from_numpy(x_list).reshape(batch_size,1).float()\n",
        "y_train0 = torch.from_numpy(y_list).reshape(batch_size,1).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-FHbIND2A34",
        "colab_type": "text"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "First we create the training data. This is a batch of random points that we pass through the BSM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SbutUBbo7r6K",
        "colab": {}
      },
      "source": [
        "# Create Training Data\n",
        "\n",
        "#batch_size = 1000\n",
        "\n",
        "# Create a list\n",
        "#a = []\n",
        "\n",
        "# Generate randomized data\n",
        "#x_train = torch.randn(batch_size, 1)\n",
        "# Modify the random data to be a stock price\n",
        "#x_train0 = np.abs(x_train*100)\n",
        "\n",
        "# Create static training data for conistency\n",
        "#x_train = torch.tensor([[100], [105], [110], [115], [120]])\n",
        "\n",
        "# Initialize GBM\n",
        "#gbm1 = Gbm()\n",
        "#option = VanillaOption()\n",
        "\n",
        "# Call the prices_bsm to get y_train\n",
        "#y_train0 = gbm1.prices_bsm(option, x_train)\n",
        "\n",
        "#print(x_train[1:10])\n",
        "#print(y_train[1:10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9VZMG4e2ziF",
        "colab_type": "text"
      },
      "source": [
        "Once we have the training data, we pass this collection of inputs and solutions into the model. With each iteration we calculate the loss and attempt to optimize the model to further reduce the loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPsSIArQEgHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalization\n",
        "\n",
        "def linear_transform(xx, l = 0, u= 1):\n",
        "  M = torch.max(xx)\n",
        "  m = torch.min(xx)\n",
        "  return (u-l)/(M-m)*(xx-m)+l, m, M, l, u\n",
        "x_train, x_m, x_M, x_l, x_u = linear_transform(x_train0, -1, 1)\n",
        "y_train, y_m, y_M, y_l, y_u = linear_transform(y_train0, 0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4hNIFisK7r6M",
        "outputId": "a51c2cd6-f7a2-45b4-e0fe-8a685468e4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(x_train.float())\n",
        "    loss = criterion(outputs, y_train.float())\n",
        "    \n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch == 0 or (epoch+1) % 50 == 0:\n",
        "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, \n",
        "                                                    num_epochs, loss.item()))\n",
        "        print(outputs[1:10])\n",
        "       \n",
        "      \n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/1000], Loss: 0.1023\n",
            "tensor([[0.3266],\n",
            "        [0.3266],\n",
            "        [0.3265],\n",
            "        [0.3264],\n",
            "        [0.3264],\n",
            "        [0.3263],\n",
            "        [0.3263],\n",
            "        [0.3262],\n",
            "        [0.3261]], grad_fn=<SliceBackward>)\n",
            "Epoch [50/1000], Loss: 0.0950\n",
            "tensor([[0.4094],\n",
            "        [0.4094],\n",
            "        [0.4094],\n",
            "        [0.4094],\n",
            "        [0.4094],\n",
            "        [0.4094],\n",
            "        [0.4095],\n",
            "        [0.4095],\n",
            "        [0.4095]], grad_fn=<SliceBackward>)\n",
            "Epoch [100/1000], Loss: 0.0946\n",
            "tensor([[0.4082],\n",
            "        [0.4084],\n",
            "        [0.4085],\n",
            "        [0.4086],\n",
            "        [0.4087],\n",
            "        [0.4088],\n",
            "        [0.4090],\n",
            "        [0.4091],\n",
            "        [0.4092]], grad_fn=<SliceBackward>)\n",
            "Epoch [150/1000], Loss: 0.0941\n",
            "tensor([[0.4068],\n",
            "        [0.4071],\n",
            "        [0.4073],\n",
            "        [0.4076],\n",
            "        [0.4078],\n",
            "        [0.4081],\n",
            "        [0.4084],\n",
            "        [0.4086],\n",
            "        [0.4089]], grad_fn=<SliceBackward>)\n",
            "Epoch [200/1000], Loss: 0.0933\n",
            "tensor([[0.4047],\n",
            "        [0.4052],\n",
            "        [0.4056],\n",
            "        [0.4061],\n",
            "        [0.4065],\n",
            "        [0.4070],\n",
            "        [0.4075],\n",
            "        [0.4079],\n",
            "        [0.4084]], grad_fn=<SliceBackward>)\n",
            "Epoch [250/1000], Loss: 0.0920\n",
            "tensor([[0.4011],\n",
            "        [0.4019],\n",
            "        [0.4027],\n",
            "        [0.4035],\n",
            "        [0.4043],\n",
            "        [0.4051],\n",
            "        [0.4060],\n",
            "        [0.4068],\n",
            "        [0.4077]], grad_fn=<SliceBackward>)\n",
            "Epoch [300/1000], Loss: 0.0894\n",
            "tensor([[0.3942],\n",
            "        [0.3956],\n",
            "        [0.3971],\n",
            "        [0.3986],\n",
            "        [0.4002],\n",
            "        [0.4017],\n",
            "        [0.4033],\n",
            "        [0.4049],\n",
            "        [0.4065]], grad_fn=<SliceBackward>)\n",
            "Epoch [350/1000], Loss: 0.0836\n",
            "tensor([[0.3789],\n",
            "        [0.3819],\n",
            "        [0.3849],\n",
            "        [0.3880],\n",
            "        [0.3911],\n",
            "        [0.3943],\n",
            "        [0.3975],\n",
            "        [0.4008],\n",
            "        [0.4040]], grad_fn=<SliceBackward>)\n",
            "Epoch [400/1000], Loss: 0.0697\n",
            "tensor([[0.3400],\n",
            "        [0.3468],\n",
            "        [0.3538],\n",
            "        [0.3609],\n",
            "        [0.3682],\n",
            "        [0.3757],\n",
            "        [0.3832],\n",
            "        [0.3908],\n",
            "        [0.3985]], grad_fn=<SliceBackward>)\n",
            "Epoch [450/1000], Loss: 0.0384\n",
            "tensor([[0.2362],\n",
            "        [0.2529],\n",
            "        [0.2703],\n",
            "        [0.2883],\n",
            "        [0.3069],\n",
            "        [0.3260],\n",
            "        [0.3454],\n",
            "        [0.3652],\n",
            "        [0.3852]], grad_fn=<SliceBackward>)\n",
            "Epoch [500/1000], Loss: 0.0077\n",
            "tensor([[0.0706],\n",
            "        [0.1010],\n",
            "        [0.1335],\n",
            "        [0.1679],\n",
            "        [0.2042],\n",
            "        [0.2422],\n",
            "        [0.2816],\n",
            "        [0.3222],\n",
            "        [0.3637]], grad_fn=<SliceBackward>)\n",
            "Epoch [550/1000], Loss: 0.0020\n",
            "tensor([[-0.0010],\n",
            "        [ 0.0325],\n",
            "        [ 0.0689],\n",
            "        [ 0.1083],\n",
            "        [ 0.1507],\n",
            "        [ 0.1958],\n",
            "        [ 0.2436],\n",
            "        [ 0.2936],\n",
            "        [ 0.3454]], grad_fn=<SliceBackward>)\n",
            "Epoch [600/1000], Loss: 0.0011\n",
            "tensor([[-0.0026],\n",
            "        [ 0.0284],\n",
            "        [ 0.0625],\n",
            "        [ 0.0998],\n",
            "        [ 0.1403],\n",
            "        [ 0.1841],\n",
            "        [ 0.2310],\n",
            "        [ 0.2808],\n",
            "        [ 0.3332]], grad_fn=<SliceBackward>)\n",
            "Epoch [650/1000], Loss: 0.0007\n",
            "tensor([[0.0047],\n",
            "        [0.0333],\n",
            "        [0.0650],\n",
            "        [0.0999],\n",
            "        [0.1382],\n",
            "        [0.1799],\n",
            "        [0.2251],\n",
            "        [0.2735],\n",
            "        [0.3250]], grad_fn=<SliceBackward>)\n",
            "Epoch [700/1000], Loss: 0.0005\n",
            "tensor([[0.0103],\n",
            "        [0.0373],\n",
            "        [0.0673],\n",
            "        [0.1005],\n",
            "        [0.1372],\n",
            "        [0.1773],\n",
            "        [0.2211],\n",
            "        [0.2684],\n",
            "        [0.3191]], grad_fn=<SliceBackward>)\n",
            "Epoch [750/1000], Loss: 0.0003\n",
            "tensor([[0.0144],\n",
            "        [0.0402],\n",
            "        [0.0690],\n",
            "        [0.1010],\n",
            "        [0.1364],\n",
            "        [0.1755],\n",
            "        [0.2182],\n",
            "        [0.2647],\n",
            "        [0.3148]], grad_fn=<SliceBackward>)\n",
            "Epoch [800/1000], Loss: 0.0003\n",
            "tensor([[0.0176],\n",
            "        [0.0425],\n",
            "        [0.0704],\n",
            "        [0.1014],\n",
            "        [0.1359],\n",
            "        [0.1741],\n",
            "        [0.2161],\n",
            "        [0.2619],\n",
            "        [0.3114]], grad_fn=<SliceBackward>)\n",
            "Epoch [850/1000], Loss: 0.0002\n",
            "tensor([[0.0201],\n",
            "        [0.0443],\n",
            "        [0.0715],\n",
            "        [0.1018],\n",
            "        [0.1356],\n",
            "        [0.1731],\n",
            "        [0.2144],\n",
            "        [0.2597],\n",
            "        [0.3088]], grad_fn=<SliceBackward>)\n",
            "Epoch [900/1000], Loss: 0.0002\n",
            "tensor([[0.0220],\n",
            "        [0.0458],\n",
            "        [0.0724],\n",
            "        [0.1022],\n",
            "        [0.1354],\n",
            "        [0.1724],\n",
            "        [0.2132],\n",
            "        [0.2580],\n",
            "        [0.3068]], grad_fn=<SliceBackward>)\n",
            "Epoch [950/1000], Loss: 0.0001\n",
            "tensor([[0.0237],\n",
            "        [0.0470],\n",
            "        [0.0731],\n",
            "        [0.1025],\n",
            "        [0.1353],\n",
            "        [0.1718],\n",
            "        [0.2122],\n",
            "        [0.2567],\n",
            "        [0.3052]], grad_fn=<SliceBackward>)\n",
            "Epoch [1000/1000], Loss: 0.0001\n",
            "tensor([[0.0249],\n",
            "        [0.0479],\n",
            "        [0.0737],\n",
            "        [0.1027],\n",
            "        [0.1352],\n",
            "        [0.1713],\n",
            "        [0.2114],\n",
            "        [0.2556],\n",
            "        [0.3039]], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7-wQ_nA3eRF",
        "colab_type": "text"
      },
      "source": [
        "## Testing the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO-I6S5oFvzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learnedfun(x):\n",
        "  out = (1-(-1))/(x_M-x_m)*(x-x_m)+(-1.)\n",
        "  out = model(out)\n",
        "  out = (y_M- y_m)*out+y_m\n",
        "  return out\n",
        "\n",
        "y_pred = learnedfun(x_train0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trvbzo52HoLF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ff30662b-35e8-478f-ff13-64409cf6d324"
      },
      "source": [
        "# Test with training data\n",
        "plt.scatter(x_train0.detach().numpy(), y_train0.detach().numpy(), label='true')\n",
        "plt.plot(x_train0.detach().numpy(), y_pred.detach().numpy(), label='pred')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEP8fdG3k/wffwBAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qZjRYQGe7r6P",
        "outputId": "58313841-923c-4a92-c038-1ebbc72bf1a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Test the Model with Random data\n",
        "\n",
        "# Generate random data\n",
        "x_0 = torch.randn(50,1)\n",
        "\n",
        "# Get BSM Prices as determined by the formula\n",
        "y_0 = gbm1.prices_bsm(option, x_)\n",
        "\n",
        "# Normalize\n",
        "x_, x_m, x_M, x_l, x_u = linear_transform(x_0)\n",
        "y_, y_m, y_M, y_l, y_u = linear_transform(x_0)\n",
        "\n",
        "# Plot x_ versus formula prices\n",
        "plt.scatter(x_0.detach().numpy(), y_0.detach().numpy(), label='true')\n",
        "\n",
        "# Get BSM Prices as determined by the model\n",
        "y_pred = learnedfun(x_0)\n",
        "\n",
        "# Plot x_ versus the model prices\n",
        "plt.scatter(x_0.detach().numpy(), y_pred.detach().numpy(), label='pred')\n",
        "\n",
        "plt.legend()\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff9a0057a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btJeLUznONYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}